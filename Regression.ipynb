{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction: Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## note: see grid_search.py for grid search code. This notebook is \n",
    "## primarily for exploration and one-off runs\n",
    "\n",
    "## imports\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from globes import taxi_dir, days_dir\n",
    "from multiprocessing import Pool, Process, cpu_count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FEATURE_COLS = ['pickup_day', \n",
    "                'pickup_hour', \n",
    "                'pickup_latitude', \n",
    "                'pickup_longitude']\n",
    "\n",
    "Y_COLS = ['dropoff_latitude', \n",
    "          'dropoff_longitude']\n",
    "\n",
    "\"\"\" get feature and label rows from filename\n",
    "\"\"\"\n",
    "def getXyAll(filename):\n",
    "    df = pd.read_csv(filename, parse_dates=['pickup_datetime', 'dropoff_datetime'])\n",
    "    \n",
    "    # get rid of zones that don't actually really exist THIS IS IMPORTANT\n",
    "    df = df.loc[df['pickup_zone_taxi'] != -1]\n",
    "    df = df.loc[df['dropoff_zone_taxi'] != -1]\n",
    "    df = df.dropna()\n",
    "    \n",
    "    df[\"pickup_day\"] = df['pickup_datetime'].apply(lambda t: t.weekday())\n",
    "    df[\"pickup_hour\"] = df['pickup_datetime'].apply(lambda t: t.hour)\n",
    "\n",
    "    df_X = df[FEATURE_COLS]\n",
    "    df_Y = df[Y_COLS]\n",
    "    return df_X, df_Y\n",
    "\n",
    "\"\"\" get feature and label rows from filename, only for Manhattan\n",
    "\"\"\"\n",
    "def getXyManhattan(filename):\n",
    "    df = pd.read_csv(filename, parse_dates=['pickup_datetime', 'dropoff_datetime'])\n",
    "\n",
    "    # get rid of zones that don't actually really exist THIS IS IMPORTANT\n",
    "    df = df.loc[df['pickup_zone_taxi'] != -1]\n",
    "    df = df.loc[df['dropoff_zone_taxi'] != -1]\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # keep only Manhattan pickups\n",
    "    df = df.loc[df['pickup_borough'] == \"Manhattan\"]\n",
    "    \n",
    "    df[\"pickup_day\"] = df['pickup_datetime'].apply(lambda t: t.weekday())\n",
    "    df[\"pickup_hour\"] = df['pickup_datetime'].apply(lambda t: t.hour)\n",
    "\n",
    "    df_X = df[FEATURE_COLS]\n",
    "    df_Y = df[Y_COLS]\n",
    "    return df_X, df_Y   \n",
    "\n",
    "\"\"\" get X, y in numpy arrays from relevant data\n",
    "\"\"\"\n",
    "def getDataNumpy(get_Xy_func):\n",
    "    num_cores = cpu_count()/2\n",
    "    print \"using \" + str(num_cores) + \" cores\"\n",
    "    pool = Pool(processes=num_cores)\n",
    "\n",
    "    filenames = [os.path.join(taxi_dir, days_dir, f) for f in os.listdir(os.path.join(taxi_dir, days_dir)) if f.endswith('csv')]\n",
    "    \n",
    "    # get X, y dataframes in parallel\n",
    "    Xy_arr = pool.map(get_Xy_func, filenames)\n",
    "    pool.terminate()\n",
    "\n",
    "    # separate out to array of X dataframes and y dataframes\n",
    "    dfs_X = map(lambda pair: pair[0], Xy_arr)\n",
    "    dfs_y = map(lambda pair: pair[1], Xy_arr)\n",
    "\n",
    "    # concatenate dataframe array into single df\n",
    "    df_X = pd.concat(dfs_X)\n",
    "    df_y = pd.concat(dfs_y)\n",
    "\n",
    "    # convert df to numpy arrays\n",
    "    X = df_X.as_matrix()\n",
    "    y = df_y.as_matrix()\n",
    "\n",
    "    print df_X.shape, df_y.shape\n",
    "    print X.shape, y.shape\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using 28 cores\n",
      "(77699460, 4) (77699460, 2)\n",
      "(77699460, 4) (77699460, 2)\n"
     ]
    }
   ],
   "source": [
    "X, y = getDataNumpy(getXyAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using 28 cores\n",
      "(65147846, 4) (65147846, 2)\n",
      "(65147846, 4) (65147846, 2)\n"
     ]
    }
   ],
   "source": [
    "Xm, ym = getDataNumpy(getXyManhattan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error,make_scorer\n",
    "from operator import add\n",
    "\n",
    "\"\"\"RMSE\n",
    "\"\"\"\n",
    "def RMSE(y, y_pred):\n",
    "    rmsevalid = np.sqrt(mean_squared_error(y,y_pred, multioutput=\"raw_values\"))\n",
    "    print \"RMSE: \" + str(rmsevalid)\n",
    "    return rmsevalid\n",
    "\n",
    "\"\"\" Random Forest Regressor\n",
    "\"\"\"\n",
    "def RandomForest(X, y, split_index=69000000):\n",
    "    X_train = X[:split_index]\n",
    "    y_train = y[:split_index]\n",
    "    \n",
    "    X_test = X[split_index:]\n",
    "    y_test = y[split_index:]\n",
    "    \n",
    "    print X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
    "    \n",
    "    ## best values for RMSE\n",
    "    reg = RandomForestRegressor(n_estimators=8, max_depth=20, n_jobs=-1, verbose=3, warm_start=True)\n",
    "        \n",
    "    reg.fit(X_train, y_train)\n",
    "    training_accuracy = reg.score(X_train, y_train)\n",
    "    valid_accuracy = reg.score(X_test, y_test)\n",
    "    rmsetrain = np.sqrt(mean_squared_error(reg.predict(X_train),y_train))\n",
    "    rmsevalid = np.sqrt(mean_squared_error(reg.predict(X_test),y_test))\n",
    "    \n",
    "    print \" R^2 (train) = %0.3f, R^2 (valid) = %0.3f, RMSE (train) = %0.3f, RMSE (valid) = %0.3f\" \\\n",
    "        % (training_accuracy, valid_accuracy, rmsetrain, rmsevalid)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69000000, 4) (69000000, 2) (8699460, 4) (8699460, 2)\n",
      "building tree 1 of 8building tree 2 of 8\n",
      "building tree 5 of 8 \n",
      "  \n",
      "building tree 4 of 8building tree 7 of 8building tree 3 of 8building tree 6 of 8building tree 8 of 8\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:  5.3min remaining: 16.0min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   8 | elapsed:  5.4min remaining:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  5.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  5.5min finished\n",
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:   18.9s remaining:   56.8s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:   19.1s remaining:   11.5s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:   19.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:   19.4s finished\n",
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:    2.5s remaining:    7.5s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    2.6s remaining:    1.6s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    2.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:   18.7s remaining:   56.0s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:   18.8s remaining:   11.3s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:   19.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:   19.5s finished\n",
      "[Parallel(n_jobs=8)]: Done   2 out of   8 | elapsed:    2.6s remaining:    7.7s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   8 | elapsed:    2.6s remaining:    1.5s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    2.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of   8 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " R^2 (train) = 0.413, R^2 (valid) = 0.387, RMSE (train) = 0.029, RMSE (valid) = 0.029\n"
     ]
    }
   ],
   "source": [
    "RandomForest(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58000000, 4) (58000000, 2) (7147846, 4) (7147846, 2)\n",
      "building tree 1 of 2building tree 2 of 2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  3.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  3.7min finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   17.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   17.8s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    2.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   16.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   16.9s finished\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    2.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " R^2 (train) = 0.257, R^2 (valid) = 0.200, RMSE (train) = 0.027, RMSE (valid) = 0.028\n"
     ]
    }
   ],
   "source": [
    "RandomForest(Xm, ym, split_index=58000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "\n",
    "def SGD(X, y):\n",
    "    kf = KFold(n_splits=6, shuffle=True)\n",
    "    res = {\n",
    "        \"train_r2\": 0.0,\n",
    "        \"valid_r2\": 0.0,\n",
    "        \"train_rmse\": [0.0, 0.0],\n",
    "        \"valid_rmse\": [0.0, 0.0]\n",
    "    }\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index] \n",
    "        y_train, y_test = y[train_index], y[test_index] \n",
    "\n",
    "        # scale data\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)  # apply same transformation to test data\n",
    "\n",
    "        reg = MultiOutputRegressor(linear_model.SGDRegressor(alpha=0.0001, eta0=0.001))\n",
    "        reg.fit(X_train, y_train)\n",
    "        res[\"train_r2\"] += reg.score(X_train, y_train)\n",
    "        res[\"valid_r2\"] += reg.score(X_test, y_test)\n",
    "        rmse_train = RMSE(reg.predict(X_train),y_train)\n",
    "        rmse_valid = RMSE(reg.predict(X_test),y_test)\n",
    "        print rmse_train, rmse_valid\n",
    "        res[\"train_rmse\"] = map(add,res[\"train_rmse\"], rmse_train)\n",
    "        res[\"valid_rmse\"] = map(add,res[\"valid_rmse\"], rmse_valid)\n",
    "\n",
    "    # average of error scores\n",
    "    # average of error scores\n",
    "    res[\"train_r2\"] = res[\"train_r2\"] / kf.get_n_splits(X) \n",
    "    res[\"valid_r2\"] = res[\"valid_r2\"] / kf.get_n_splits(X) \n",
    "    res[\"train_rmse\"][0] = res[\"train_rmse\"][0] / kf.get_n_splits(X) \n",
    "    res[\"train_rmse\"][1] = res[\"train_rmse\"][1] / kf.get_n_splits(X) \n",
    "    res[\"valid_rmse\"][0] = res[\"valid_rmse\"][0] / kf.get_n_splits(X) \n",
    "    res[\"valid_rmse\"][1] = res[\"valid_rmse\"][1] / kf.get_n_splits(X) \n",
    "\n",
    "    print \" R^2 (train) = %0.3f, R^2 (valid) = %0.3f, RMSE (train) = %f, %f, RMSE (valid) = %f, %f\" \\\n",
    "        % (res[\"train_r2\"], res[\"valid_r2\"], res[\"train_rmse\"][0],res[\"train_rmse\"][1], res[\"valid_rmse\"][0],res[\"valid_rmse\"][1])\n",
    "    print \"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SGD(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SGD(Xm, ym)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
